{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\veera\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\veera\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "c:\\Users\\veera\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "usage: ipykernel_launcher.py [-h] --data_dir DATA_DIR\n",
      "ipykernel_launcher.py: error: the following arguments are required: --data_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veera\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:3450: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import lmdb\n",
    "from path import Path\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_dir', type=Path, required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# 2GB is enough for IAM dataset\n",
    "assert not (args.data_dir / 'lmdb').exists()\n",
    "env = lmdb.open(str(args.data_dir / 'lmdb'), map_size=1024 * 1024 * 1024 * 2)\n",
    "\n",
    "# go over all png files\n",
    "fn_imgs = list((args.data_dir / 'img').walkfiles('*.png'))\n",
    "\n",
    "# and put the imgs into lmdb as pickled grayscale imgs\n",
    "with env.begin(write=True) as txn:\n",
    "    for i, fn_img in enumerate(fn_imgs):\n",
    "        print(i, len(fn_imgs))\n",
    "        img = cv2.imread(fn_img, cv2.IMREAD_GRAYSCALE)\n",
    "        basename = fn_img.basename()\n",
    "        txn.put(basename.encode(\"ascii\"), pickle.dumps(img))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from typing import Tuple\n",
    "\n",
    "import cv2\n",
    "import lmdb\n",
    "import numpy as np\n",
    "from path import Path\n",
    "\n",
    "Sample = namedtuple('Sample', 'gt_text, file_path')\n",
    "Batch = namedtuple('Batch', 'imgs, gt_texts, batch_size')\n",
    "\n",
    "\n",
    "class DataLoaderIAM:\n",
    "    \"\"\"\n",
    "    Loads data which corresponds to IAM format,\n",
    "    see: http://www.fki.inf.unibe.ch/databases/iam-handwriting-database\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_dir: Path,\n",
    "                 batch_size: int,\n",
    "                 data_split: float = 0.95,\n",
    "                 fast: bool = True) -> None:\n",
    "        \"\"\"Loader for dataset.\"\"\"\n",
    "\n",
    "        assert data_dir.exists()\n",
    "\n",
    "        self.fast = fast\n",
    "        if fast:\n",
    "            self.env = lmdb.open(str(data_dir / 'lmdb'), readonly=True)\n",
    "\n",
    "        self.data_augmentation = False\n",
    "        self.curr_idx = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.samples = []\n",
    "\n",
    "        f = open(data_dir / 'gt/words.txt')\n",
    "        chars = set()\n",
    "        bad_samples_reference = ['a01-117-05-02', 'r06-022-03-05']  # known broken images in IAM dataset\n",
    "        for line in f:\n",
    "            # ignore empty and comment lines\n",
    "            line = line.strip()\n",
    "            if not line or line[0] == '#':\n",
    "                continue\n",
    "\n",
    "            line_split = line.split(' ')\n",
    "            assert len(line_split) >= 9\n",
    "\n",
    "            # filename: part1-part2-part3 --> part1/part1-part2/part1-part2-part3.png\n",
    "            file_name_split = line_split[0].split('-')\n",
    "            file_name_subdir1 = file_name_split[0]\n",
    "            file_name_subdir2 = f'{file_name_split[0]}-{file_name_split[1]}'\n",
    "            file_base_name = line_split[0] + '.png'\n",
    "            file_name = data_dir / 'img' / file_name_subdir1 / file_name_subdir2 / file_base_name\n",
    "\n",
    "            if line_split[0] in bad_samples_reference:\n",
    "                print('Ignoring known broken image:', file_name)\n",
    "                continue\n",
    "\n",
    "            # GT text are columns starting at 9\n",
    "            gt_text = ' '.join(line_split[8:])\n",
    "            chars = chars.union(set(list(gt_text)))\n",
    "\n",
    "            # put sample into list\n",
    "            self.samples.append(Sample(gt_text, file_name))\n",
    "\n",
    "        # split into training and validation set: 95% - 5%\n",
    "        split_idx = int(data_split * len(self.samples))\n",
    "        self.train_samples = self.samples[:split_idx]\n",
    "        self.validation_samples = self.samples[split_idx:]\n",
    "\n",
    "        # put words into lists\n",
    "        self.train_words = [x.gt_text for x in self.train_samples]\n",
    "        self.validation_words = [x.gt_text for x in self.validation_samples]\n",
    "\n",
    "        # start with train set\n",
    "        self.train_set()\n",
    "\n",
    "        # list of all chars in dataset\n",
    "        self.char_list = sorted(list(chars))\n",
    "\n",
    "    def train_set(self) -> None:\n",
    "        \"\"\"Switch to randomly chosen subset of training set.\"\"\"\n",
    "        self.data_augmentation = True\n",
    "        self.curr_idx = 0\n",
    "        random.shuffle(self.train_samples)\n",
    "        self.samples = self.train_samples\n",
    "        self.curr_set = 'train'\n",
    "\n",
    "    def validation_set(self) -> None:\n",
    "        \"\"\"Switch to validation set.\"\"\"\n",
    "        self.data_augmentation = False\n",
    "        self.curr_idx = 0\n",
    "        self.samples = self.validation_samples\n",
    "        self.curr_set = 'val'\n",
    "\n",
    "    def get_iterator_info(self) -> Tuple[int, int]:\n",
    "        \"\"\"Current batch index and overall number of batches.\"\"\"\n",
    "        if self.curr_set == 'train':\n",
    "            num_batches = int(np.floor(len(self.samples) / self.batch_size))  # train set: only full-sized batches\n",
    "        else:\n",
    "            num_batches = int(np.ceil(len(self.samples) / self.batch_size))  # val set: allow last batch to be smaller\n",
    "        curr_batch = self.curr_idx // self.batch_size + 1\n",
    "        return curr_batch, num_batches\n",
    "\n",
    "    def has_next(self) -> bool:\n",
    "        \"\"\"Is there a next element?\"\"\"\n",
    "        if self.curr_set == 'train':\n",
    "            return self.curr_idx + self.batch_size <= len(self.samples)  # train set: only full-sized batches\n",
    "        else:\n",
    "            return self.curr_idx < len(self.samples)  # val set: allow last batch to be smaller\n",
    "\n",
    "    def _get_img(self, i: int) -> np.ndarray:\n",
    "        if self.fast:\n",
    "            with self.env.begin() as txn:\n",
    "                basename = Path(self.samples[i].file_path).basename()\n",
    "                data = txn.get(basename.encode(\"ascii\"))\n",
    "                img = pickle.loads(data)\n",
    "        else:\n",
    "            img = cv2.imread(self.samples[i].file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def get_next(self) -> Batch:\n",
    "        \"\"\"Get next element.\"\"\"\n",
    "        batch_range = range(self.curr_idx, min(self.curr_idx + self.batch_size, len(self.samples)))\n",
    "\n",
    "        imgs = [self._get_img(i) for i in batch_range]\n",
    "        gt_texts = [self.samples[i].gt_text for i in batch_range]\n",
    "\n",
    "        self.curr_idx += self.batch_size\n",
    "        return Batch(imgs, gt_texts, len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3695890367.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install editdistance\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install editdistance\n",
    "python3 -m pip install --extra-index-url https://pypi.nvidia.com tensorrt-bindings==8.6.1 tensorrt-libs==8.6.1\n",
    "python3 -m pip install -U tensorflow[and-cuda]\n",
    "# Verify the installation:\n",
    "python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\Handwritting recognition system\\handwritten.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Handwritting%20recognition%20system/handwritten.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpath\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Handwritting%20recognition%20system/handwritten.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataloader_iam\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoaderIAM, Batch\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Handwritting%20recognition%20system/handwritten.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m Model, DecoderType\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Handwritting%20recognition%20system/handwritten.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpreprocessor\u001b[39;00m \u001b[39mimport\u001b[39;00m Preprocessor\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Handwritting%20recognition%20system/handwritten.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mFilePaths\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Handwritting recognition system\\model.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List, Tuple\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataloader_iam\u001b[39;00m \u001b[39mimport\u001b[39;00m Batch\n\u001b[0;32m     10\u001b[0m \u001b[39m# Disable eager mode\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "from typing import Tuple, List\n",
    "\n",
    "import cv2\n",
    "import editdistance\n",
    "from path import Path\n",
    "\n",
    "from dataloader_iam import DataLoaderIAM, Batch\n",
    "from model import Model, DecoderType\n",
    "from preprocessor import Preprocessor\n",
    "\n",
    "\n",
    "class FilePaths:\n",
    "    \"\"\"Filenames and paths to data.\"\"\"\n",
    "    fn_char_list = '../model/charList.txt'\n",
    "    fn_summary = '../model/summary.json'\n",
    "    fn_corpus = '../data/corpus.txt'\n",
    "\n",
    "\n",
    "def get_img_height() -> int:\n",
    "    \"\"\"Fixed height for NN.\"\"\"\n",
    "    return 32\n",
    "\n",
    "\n",
    "def get_img_size(line_mode: bool = False) -> Tuple[int, int]:\n",
    "    \"\"\"Height is fixed for NN, width is set according to training mode (single words or text lines).\"\"\"\n",
    "    if line_mode:\n",
    "        return 256, get_img_height()\n",
    "    return 128, get_img_height()\n",
    "\n",
    "\n",
    "def write_summary(average_train_loss: List[float], char_error_rates: List[float], word_accuracies: List[float]) -> None:\n",
    "    \"\"\"Writes training summary file for NN.\"\"\"\n",
    "    with open(FilePaths.fn_summary, 'w') as f:\n",
    "        json.dump({'averageTrainLoss': average_train_loss, 'charErrorRates': char_error_rates, 'wordAccuracies': word_accuracies}, f)\n",
    "\n",
    "\n",
    "def char_list_from_file() -> List[str]:\n",
    "    with open(FilePaths.fn_char_list) as f:\n",
    "        return list(f.read())\n",
    "\n",
    "\n",
    "def train(model: Model,\n",
    "          loader: DataLoaderIAM,\n",
    "          line_mode: bool,\n",
    "          early_stopping: int = 25) -> None:\n",
    "    \"\"\"Trains NN.\"\"\"\n",
    "    epoch = 0  # number of training epochs since start\n",
    "    summary_char_error_rates = []\n",
    "    summary_word_accuracies = []\n",
    "\n",
    "    train_loss_in_epoch = []\n",
    "    average_train_loss = []\n",
    "\n",
    "    preprocessor = Preprocessor(get_img_size(line_mode), data_augmentation=True, line_mode=line_mode)\n",
    "    best_char_error_rate = float('inf')  # best validation character error rate\n",
    "    no_improvement_since = 0  # number of epochs no improvement of character error rate occurred\n",
    "    # stop training after this number of epochs without improvement\n",
    "    while True:\n",
    "        epoch += 1\n",
    "        print('Epoch:', epoch)\n",
    "\n",
    "        # train\n",
    "        print('Train NN')\n",
    "        loader.train_set()\n",
    "        while loader.has_next():\n",
    "            iter_info = loader.get_iterator_info()\n",
    "            batch = loader.get_next()\n",
    "            batch = preprocessor.process_batch(batch)\n",
    "            loss = model.train_batch(batch)\n",
    "            print(f'Epoch: {epoch} Batch: {iter_info[0]}/{iter_info[1]} Loss: {loss}')\n",
    "            train_loss_in_epoch.append(loss)\n",
    "\n",
    "        # validate\n",
    "        char_error_rate, word_accuracy = validate(model, loader, line_mode)\n",
    "\n",
    "        # write summary\n",
    "        summary_char_error_rates.append(char_error_rate)\n",
    "        summary_word_accuracies.append(word_accuracy)\n",
    "        average_train_loss.append((sum(train_loss_in_epoch)) / len(train_loss_in_epoch))\n",
    "        write_summary(average_train_loss, summary_char_error_rates, summary_word_accuracies)\n",
    "\n",
    "        # reset train loss list\n",
    "        train_loss_in_epoch = []\n",
    "\n",
    "        # if best validation accuracy so far, save model parameters\n",
    "        if char_error_rate < best_char_error_rate:\n",
    "            print('Character error rate improved, save model')\n",
    "            best_char_error_rate = char_error_rate\n",
    "            no_improvement_since = 0\n",
    "            model.save()\n",
    "        else:\n",
    "            print(f'Character error rate not improved, best so far: {best_char_error_rate * 100.0}%')\n",
    "            no_improvement_since += 1\n",
    "\n",
    "        # stop training if no more improvement in the last x epochs\n",
    "        if no_improvement_since >= early_stopping:\n",
    "            print(f'No more improvement for {early_stopping} epochs. Training stopped.')\n",
    "            break\n",
    "\n",
    "\n",
    "def validate(model: Model, loader: DataLoaderIAM, line_mode: bool) -> Tuple[float, float]:\n",
    "    \"\"\"Validates NN.\"\"\"\n",
    "    print('Validate NN')\n",
    "    loader.validation_set()\n",
    "    preprocessor = Preprocessor(get_img_size(line_mode), line_mode=line_mode)\n",
    "    num_char_err = 0\n",
    "    num_char_total = 0\n",
    "    num_word_ok = 0\n",
    "    num_word_total = 0\n",
    "    while loader.has_next():\n",
    "        iter_info = loader.get_iterator_info()\n",
    "        print(f'Batch: {iter_info[0]} / {iter_info[1]}')\n",
    "        batch = loader.get_next()\n",
    "        batch = preprocessor.process_batch(batch)\n",
    "        recognized, _ = model.infer_batch(batch)\n",
    "\n",
    "        print('Ground truth -> Recognized')\n",
    "        for i in range(len(recognized)):\n",
    "            num_word_ok += 1 if batch.gt_texts[i] == recognized[i] else 0\n",
    "            num_word_total += 1\n",
    "            dist = editdistance.eval(recognized[i], batch.gt_texts[i])\n",
    "            num_char_err += dist\n",
    "            num_char_total += len(batch.gt_texts[i])\n",
    "            print('[OK]' if dist == 0 else '[ERR:%d]' % dist, '\"' + batch.gt_texts[i] + '\"', '->',\n",
    "                  '\"' + recognized[i] + '\"')\n",
    "\n",
    "    # print validation result\n",
    "    char_error_rate = num_char_err / num_char_total\n",
    "    word_accuracy = num_word_ok / num_word_total\n",
    "    print(f'Character error rate: {char_error_rate * 100.0}%. Word accuracy: {word_accuracy * 100.0}%.')\n",
    "    return char_error_rate, word_accuracy\n",
    "\n",
    "\n",
    "def infer(model: Model, fn_img: Path) -> None:\n",
    "    \"\"\"Recognizes text in image provided by file path.\"\"\"\n",
    "    img = cv2.imread(fn_img, cv2.IMREAD_GRAYSCALE)\n",
    "    assert img is not None\n",
    "\n",
    "    preprocessor = Preprocessor(get_img_size(), dynamic_width=True, padding=16)\n",
    "    img = preprocessor.process_img(img)\n",
    "\n",
    "    batch = Batch([img], None, 1)\n",
    "    recognized, probability = model.infer_batch(batch, True)\n",
    "    print(f'Recognized: \"{recognized[0]}\"')\n",
    "    print(f'Probability: {probability[0]}')\n",
    "\n",
    "\n",
    "def parse_args() -> argparse.Namespace:\n",
    "    \"\"\"Parses arguments from the command line.\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--mode', choices=['train', 'validate', 'infer'], default='infer')\n",
    "    parser.add_argument('--decoder', choices=['bestpath', 'beamsearch', 'wordbeamsearch'], default='bestpath')\n",
    "    parser.add_argument('--batch_size', help='Batch size.', type=int, default=100)\n",
    "    parser.add_argument('--data_dir', help='Directory containing IAM dataset.', type=Path, required=False)\n",
    "    parser.add_argument('--fast', help='Load samples from LMDB.', action='store_true')\n",
    "    parser.add_argument('--line_mode', help='Train to read text lines instead of single words.', action='store_true')\n",
    "    parser.add_argument('--img_file', help='Image used for inference.', type=Path, default='../data/word.png')\n",
    "    parser.add_argument('--early_stopping', help='Early stopping epochs.', type=int, default=25)\n",
    "    parser.add_argument('--dump', help='Dump output of NN to CSV file(s).', action='store_true')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function.\"\"\"\n",
    "\n",
    "    # parse arguments and set CTC decoder\n",
    "    args = parse_args()\n",
    "    decoder_mapping = {'bestpath': DecoderType.BestPath,\n",
    "                       'beamsearch': DecoderType.BeamSearch,\n",
    "                       'wordbeamsearch': DecoderType.WordBeamSearch}\n",
    "    decoder_type = decoder_mapping[args.decoder]\n",
    "\n",
    "    # train the model\n",
    "    if args.mode == 'train':\n",
    "        loader = DataLoaderIAM(args.data_dir, args.batch_size, fast=args.fast)\n",
    "\n",
    "        # when in line mode, take care to have a whitespace in the char list\n",
    "        char_list = loader.char_list\n",
    "        if args.line_mode and ' ' not in char_list:\n",
    "            char_list = [' '] + char_list\n",
    "\n",
    "        # save characters and words\n",
    "        with open(FilePaths.fn_char_list, 'w') as f:\n",
    "            f.write(''.join(char_list))\n",
    "\n",
    "        with open(FilePaths.fn_corpus, 'w') as f:\n",
    "            f.write(' '.join(loader.train_words + loader.validation_words))\n",
    "\n",
    "        model = Model(char_list, decoder_type)\n",
    "        train(model, loader, line_mode=args.line_mode, early_stopping=args.early_stopping)\n",
    "\n",
    "    # evaluate it on the validation set\n",
    "    elif args.mode == 'validate':\n",
    "        loader = DataLoaderIAM(args.data_dir, args.batch_size, fast=args.fast)\n",
    "        model = Model(char_list_from_file(), decoder_type, must_restore=True)\n",
    "        validate(model, loader, args.line_mode)\n",
    "\n",
    "    # infer text on test image\n",
    "    elif args.mode == 'infer':\n",
    "        model = Model(char_list_from_file(), decoder_type, must_restore=True, dump=args.dump)\n",
    "        infer(model, args.img_file)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
